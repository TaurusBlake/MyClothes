import json
import os
from dotenv import load_dotenv
from elasticsearch import Elasticsearch
# 1. ä¿®æ”¹ Importsï¼šå°å…¥ Gemini çš„ Chat Model
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# --- 1. è¨­å®š ---
# 2. ä¿®æ”¹è¨­å®šèˆ‡èªè­‰ï¼šè¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

ES_HOST = "http://localhost:9200"
INDEX_NAME = "virtual_closet"
PROMPT_FOLDER = "./prompts"
# 3. ä¿®æ”¹è¨­å®šèˆ‡èªè­‰ï¼šé¸æ“‡ Gemini æ¨¡å‹
# å³ä½¿æ‚¨æåˆ° gemini-2.5-proï¼Œç›®å‰ API ä¸­æœ€ç©©å®šä¸”æ¨è–¦çš„é ‚ç´šæ¨¡å‹æ˜¯ gemini-1.5-pro-latest
DATA_MODEL = "gemini-1.5-flash" 

# --- 2. è¼”åŠ©å‡½å¼ ---
def load_prompt(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

# 4. æ›´æ–°å‡½å¼å‹åˆ¥æç¤ºï¼šå°‡ ChatOllama æ›¿æ›ç‚º ChatGoogleGenerativeAI
def generate_es_queries(user_request: str, llm: ChatGoogleGenerativeAI) -> dict:
    """æ­¥é©Ÿ 1: å°‡è‡ªç„¶èªè¨€è½‰æ›ç‚º Elasticsearch æŸ¥è©¢"""
    print(f"\n[1/4] ğŸ§  æ­£åœ¨å°‡ '{user_request}' è½‰æ›ç‚º ES æŸ¥è©¢ (ä½¿ç”¨ Gemini)...")
    
    prompt_template_str = load_prompt(os.path.join(PROMPT_FOLDER, "3_rag_query_prompt.txt"))
    prompt_template = ChatPromptTemplate.from_template(prompt_template_str)
    
    chain = prompt_template | llm | StrOutputParser()
    
    query_str = chain.invoke({"user_request": user_request})
    print(f"  -> ç”Ÿæˆçš„æŸ¥è©¢æŒ‡ä»¤: {query_str}")
    
    if query_str.strip().startswith("```json"):
        cleaned_query_str = query_str.strip()[7:-3].strip()
    else:
        cleaned_query_str = query_str
    
    return json.loads(cleaned_query_str)

def search_clothes(es_client: Elasticsearch, query: dict, size: int = 3) -> list:
    """æ­¥é©Ÿ 2: åœ¨ Elasticsearch ä¸­æœå°‹è¡£æœ"""
    print(f"\n[2/4] ğŸ” æ­£åœ¨ Elasticsearch ä¸­æœå°‹...")
    response = es_client.search(index=INDEX_NAME, query=query, size=size)
    hits = [hit['_source'] for hit in response['hits']['hits']]
    print(f"  -> æ‰¾åˆ°äº† {len(hits)} ä»¶ç›¸ç¬¦çš„è¡£ç‰©ã€‚")
    return hits

# 4. æ›´æ–°å‡½å¼å‹åˆ¥æç¤ºï¼šå°‡ ChatOllama æ›¿æ›ç‚º ChatGoogleGenerativeAI
def generate_recommendation_text(outfits: list, user_request: str, llm: ChatGoogleGenerativeAI) -> str:
    """æ­¥é©Ÿ 4: ç”Ÿæˆäººæ€§åŒ–çš„æ¨è–¦æ–‡æ¡ˆ"""
    print(f"\n[4/4] âœï¸ æ­£åœ¨ç”Ÿæˆæ¨è–¦æ–‡æ¡ˆ (ä½¿ç”¨ Gemini)...")

    context = f"ä½¿ç”¨è€…çš„éœ€æ±‚æ˜¯ï¼š'{user_request}'ã€‚\n"
    context += "æ ¹æ“šéœ€æ±‚ï¼Œæˆ‘ç‚ºä»–æ­é…äº†ä»¥ä¸‹å¹¾å¥—ç©¿æ­ï¼š\n"
    for i, (top, bottom) in enumerate(outfits):
        context += f"\nå¥—è£ {i+1}:\n"
        context += f"- ä¸Šè¡£: {top['tags']['sub_category']} (é¢¨æ ¼: {', '.join(top['tags']['style_tags'])})\n"
        context += f"- ä¸‹è‘—: {bottom['tags']['sub_category']} (é¢¨æ ¼: {', '.join(bottom['tags']['style_tags'])})\n"

    prompt = f"""
    You are a friendly and professional fashion stylist.
    Based on the following context, write a short, encouraging, and descriptive recommendation summary for the user.
    Address the user directly and explain in 1-2 sentences why these combinations work for their request.
    Keep the language natural and engaging. Speak in Traditional Chinese.

    CONTEXT:
    {context}

    YOUR RECOMMENDATION:
    """
    
    return llm.invoke(prompt).content

def main():
    if not GOOGLE_API_KEY:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° GOOGLE_API_KEYã€‚è«‹ç¢ºèªæ‚¨çš„ .env æª”æ¡ˆå·²è¨­å®šæ­£ç¢ºã€‚")
        return

    user_request = "æˆ‘æ˜å¤©è¦å»éƒŠå¤–è¸é’ï¼Œæˆ‘è©²æ€éº¼æ­é…å‘¢ï¼Ÿ"
    
    # 5. ä¿®æ”¹æ¨¡å‹åˆå§‹åŒ–ï¼šä½¿ç”¨ ChatGoogleGenerativeAI
    print(f"æ­£åœ¨åˆå§‹åŒ– Gemini æ¨¡å‹: {DATA_MODEL}")
    data_expert = ChatGoogleGenerativeAI(model=DATA_MODEL, google_api_key=GOOGLE_API_KEY, temperature=0.5)
    
    es = Elasticsearch(hosts=[ES_HOST])

    try:
        es_queries = generate_es_queries(user_request, data_expert)
        
        top_results = search_clothes(es, es_queries["top_query"])
        bottom_results = search_clothes(es, es_queries["bottom_query"])

        if not top_results or not bottom_results:
            print("\nâŒ æŠ±æ­‰ï¼Œæ‚¨çš„è¡£æ«¥ä¸­æ‰¾ä¸åˆ°è¶³å¤ çš„è¡£ç‰©ä¾†é€²è¡Œæ­é…ã€‚")
            return
            
        num_outfits = min(len(top_results), len(bottom_results), 3)
        outfits = []
        for i in range(num_outfits):
            outfits.append((top_results[i], bottom_results[i]))
        print(f"\n[3/4] ğŸ‘•ğŸ‘– å·²æˆåŠŸçµ„åˆ {num_outfits} å¥—ç©¿æ­ã€‚")

        recommendation_text = generate_recommendation_text(outfits, user_request, data_expert)

        print("\n" + "="*50)
        print("âœ¨ ç‚ºæ‚¨å°ˆå±¬çš„ç©¿æ­å»ºè­° âœ¨")
        print("="*50)
        print(recommendation_text)
        print("\n--- æ¨è–¦çµ„åˆè©³æƒ… ---")
        for i, (top, bottom) in enumerate(outfits):
            print(f"\nçµ„åˆ {i+1}:")
            print(f"  - ä¸Šè¡£ ğŸ‘š: {top['image_path']}")
            print(f"  - ä¸‹è‘— ğŸ‘–: {bottom['image_path']}")
        print("="*50)

    except Exception as e:
        print(f"\nâŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()